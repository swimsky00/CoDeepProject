{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\datacommand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import pytesseract\n",
    "# from PIL import Image\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "# import openai\n",
    "# import pymongo\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitz\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "# pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe' ## Tesseract-OCR 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = ['part1.txt','part2.vtt','part3.vtt','part4.vtt','part5.vtt']\n",
    "test_name = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "for file_name in train_name:\n",
    "    with open(file_name, \"r\") as f:\n",
    "        train_file = f.readlines() \n",
    "    train_list.extend(train_file)\n",
    "\n",
    "with open(test_name, \"r\") as f:\n",
    "    test_list = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WEBVTT\\n',\n",
       " '\\n',\n",
       " '00:00.000 --> 00:08.400\\n',\n",
       " '네 중간고사전 마지막 수업을 시작하겠습니다. 오늘은 지도학습에 대한 여섯번째 수업이고요.\\n',\n",
       " '\\n',\n",
       " '00:10.580 --> 00:16.820\\n',\n",
       " '저번 시간까지 다양한 지도학습 알고지맨에 대해서 다뤘고, 오늘은 Neural Network에 대해서 다루게 될 예정입니다.\\n',\n",
       " '저번 시간까지 다양한 지도학습 알고리즘에 대해서 다뤘고, 오늘은 Neural Network에 대해서 다루게 될 예정입니다.\\n',\n",
       " '\\n',\n",
       " '00:17.000 --> 00:21.680\\n',\n",
       " '그래서 Neural Network가 어떻게 클래시피케이션 또는 리그레이션 문제에 적용이 될 수 있고,\\n',\n",
       " '\\n',\n",
       " '00:22.040 --> 00:27.380\\n',\n",
       " '그리고 또 어떻게 우리가 사이클런을 이용해서 구현할 수 있을지에 대해서 다룰 예정이고요.\\n',\n",
       " '그리고 또 어떻게 우리가 사이킷런을 이용해서 구현할 수 있을지에 대해서 다룰 예정이고요.\\n',\n",
       " '\\n',\n",
       " '00:27.380 --> 00:35.680\\n',\n",
       " '그 다음에는 이제 우리가 전체적인 슈퍼바이스 러닝 프레임웍에서 고려할 만한 다양한 사양들에 대해서 추가로 다루게 될 예정입니다.\\n',\n",
       " '그 다음에는 이제 우리가 전체적인 슈퍼바이스 러닝 프레임웍에서 고려할 만한 다양한 사안들에 대해서 추가로 다루게 될 예정입니다.\\n',\n",
       " '\\n',\n",
       " '00:37.400 --> 00:38.700\\n',\n",
       " '그래서 Neural Network부터 보겠습니다.\\n',\n",
       " '\\n',\n",
       " '00:40.560 --> 00:49.200\\n',\n",
       " '우리가 Neural Network, 신경망이죠. 신경망을 이야기할 땐 우리가 제일 먼저 떠올릴 수 있는 게 생물학적인 신경망을 떠올릴 수 있습니다.\\n',\n",
       " '\\n',\n",
       " '00:49.460 --> 00:53.620\\n',\n",
       " '우리 인간의 뇌도 하나의 신경망의 형태를 가지고 있다고 이야기를 하죠.\\n',\n",
       " '우리 인간의 뇌도 하나의 신경망의 형태를 가지고 있다고 이야기를 하죠.\\n',\n",
       " '\\n',\n",
       " '00:53.620 --> 00:56.620\\n',\n",
       " '그래서 여러 개의 신경세포로 구성된 신경망입니다.\\n',\n",
       " '그래서 여러 개의 신경세포로 구성된 신경망입니다.\\n',\n",
       " '\\n',\n",
       " '00:57.380 --> 01:11.760\\n',\n",
       " '그래서 역사적으로 다양한 연구자들이, 생물학자들도 그렇고 실무역자, 의사, 다양한 연구자들이 그리고 뉴로사이언티스트도 있죠.\\n',\n",
       " '그래서 역사적으로 다양한 연구자들이, 생물학자들도 그렇고 심리학자, 의사, 다양한 연구자들이 그리고 뉴로사이언티스트도 있죠.\\n',\n",
       " '\\n',\n",
       " '01:12.060 --> 01:18.200\\n',\n",
       " '이런 뇌의 어떤 작동 방식을 이해하는 데 많은 노력들이 기울어왔습니다.\\n',\n",
       " '\\n',\n",
       " '01:18.200 --> 01:26.200\\n',\n",
       " '그리고 보면 우리가 알려진 바는 뇌라는 게 어떤 신경세포입니다.\\n',\n",
       " '\\n',\n",
       " '01:27.380 --> 01:37.440\\n',\n",
       " '신경세포의 어떤 단위로 구성이 되어서 여러 개의 신경세포가 연결되어 있고 이런 연결로 통해서 우리가 정보도 전달하고 어떤 인지도 하고\\n',\n",
       " '\\n',\n",
       " '01:37.440 --> 01:42.580\\n',\n",
       " '뭐 그렇다 이런 것들이 알려져 있다. 그리고 정보를 저장하기도 하고 이런 것들이 알려져 있어 왔습니다.\\n',\n",
       " '\\n',\n",
       " '01:43.280 --> 01:48.300\\n',\n",
       " '그래서 아마 고등학교 때 생물 수업을 들으시면 이런 가벼운 얘기들을 들여왔을 거라고 생각이 듭니다.\\n',\n",
       " '\\n',\n",
       " '01:48.980 --> 01:52.240\\n',\n",
       " '그런데 우리가 오늘 이야기하는 건 생물학적인 신경망이 아니고요.\\n',\n",
       " '\\n',\n",
       " '01:52.240 --> 01:57.240\\n',\n",
       " '이런 아이디어를 어떻게 우리가 데이터로부터 어떤 모델을,\\n',\n",
       " '\\n',\n",
       " '01:57.380 --> 02:02.880\\n',\n",
       " '어떤 모델을 학습하는 관점으로 끌고 올 수 있을지에 대한 이야기를 짚어보려고 합니다.\\n',\n",
       " '\\n',\n",
       " '02:02.880 --> 02:15.880\\n',\n",
       " '그래서 이 뇌의 아키텍처, 그러니까 biological neural network를 우리가 어떻게 지도학습이란 모델로 형태로 구성할 것인지에 대한 노력들이 있었고요.\\n',\n",
       " '\\n',\n",
       " '02:15.880 --> 02:22.880\\n',\n",
       " '그래서 이런 biological neural network이 어떻게 작동하는지에 대한 아이디어를 가지고 와서 우리가 이런 모델을 설계해보자.\\n',\n",
       " '\\n',\n",
       " '02:22.880 --> 02:26.880\\n',\n",
       " '이런 식의 노력으로 이 인공신경망, artificial neural network라는 게 이루어졌습니다.\\n',\n",
       " '이런 식의 노력으로 이 인공신경망, artificial neural network라는 게 이루어졌습니다.\\n',\n",
       " '\\n',\n",
       " '02:27.380 --> 02:37.380\\n',\n",
       " '그리고 최근에는 딥러닝이라는 이름으로 상당히 이런 인공신경망 구조의 활용이 조금 더 점차 활발하게 이루어지고 있습니다.\\n',\n",
       " '\\n',\n",
       " '02:37.380 --> 02:42.380\\n',\n",
       " '그리고 조금 더 어떤 인간의 뇌에 어떤 작용 같은 것을 아이디어에 따와서\\n',\n",
       " '\\n',\n",
       " '02:42.380 --> 02:48.380\\n',\n",
       " '조금 더 이런 데이터로부터 어떻게 좀 더 잘 배워볼까,\\n',\n",
       " '\\n',\n",
       " '02:48.380 --> 02:53.380\\n',\n",
       " '이 artificial neural network을 어떻게 잘 학습시켜볼까라는 노력들도 꾸준히 이루어지고 있기도 합니다.\\n',\n",
       " '\\n',\n",
       " '02:53.380 --> 02:56.380\\n',\n",
       " '그래서 이런 맥락에서 우리가 다룰 내용은 artificial neural network입니다.\\n',\n",
       " '\\n',\n",
       " '02:57.380 --> 03:07.380\\n',\n",
       " '그래서 이 다음 페이지부터 우리가 neural network라고 한다면 biological neural network이 아니라 artificial neural network이라고 이해하시면 될 것 같습니다.\\n',\n",
       " '\\n',\n",
       " '03:07.380 --> 03:11.380\\n',\n",
       " '그래서 neural network은 앞에서 이야기를 했지만,\\n',\n",
       " '\\n',\n",
       " '03:11.380 --> 03:17.380\\n',\n",
       " '우리가 최근에, neural network가 사실은 한 1970, 1980년대 이때 상당히 각광을 받는 알고리즘이었는데\\n',\n",
       " '\\n',\n",
       " '03:17.380 --> 03:21.380\\n',\n",
       " '그러다가 이제 한동안 인기가 많이 식었었고요.\\n',\n",
       " '\\n',\n",
       " '03:21.380 --> 03:26.380\\n',\n",
       " '그리고 저번 시간에 다뤘던 서포트 패턴 머신이 2000년 초반에는 상당히 인기를 부과하는,\\n',\n",
       " '\\n',\n",
       " '03:26.380 --> 03:30.380\\n',\n",
       " '아주 모두가 이야기하고 모두가 사용하는 알고리즘이었다.\\n',\n",
       " '\\n',\n",
       " '03:30.380 --> 03:38.380\\n',\n",
       " '그런데 현재와서는 다시, 다시 neural network가 다시 전성기를 맞이하고 있다라고 이야기합니다.\\n',\n",
       " '\\n',\n",
       " '03:38.380 --> 03:42.380\\n',\n",
       " '그래서 이 neural network를 사용하는 이제 한 분 분야에서 우리가 딥러닝을 이야기합니다.\\n',\n",
       " '그래서 이 neural network를 사용하는 이제 학문 분야에서 우리가 딥러닝을 이야기합니다.\\n',\n",
       " '\\n',\n",
       " '03:42.380 --> 03:46.380\\n',\n",
       " '그래서 머신러닝의, 일반적으로 머신러닝의 부분 집합으로서 딥러닝을 이야기하는데요.\\n',\n",
       " '\\n',\n",
       " '03:46.380 --> 03:53.380\\n',\n",
       " '이 딥러닝이라는 어떤 트렌드에 오면서 인공 시그마가 우리가 조금 더 복잡하게 만들고,\\n',\n",
       " '이 딥러닝이라는 어떤 트렌드에 오면서 인공 신경망을 우리가 조금 더 복잡하게 만들고,\\n',\n",
       " '\\n',\n",
       " '03:53.380 --> 03:56.380\\n',\n",
       " '단순하게 앞에서 소개했던 그냥 단순한 벡터 형태의 인공 시그마\\n',\n",
       " '단순하게 앞에서 소개했던 그냥 단순한 벡터 형태의 인공 신경망\\n',\n",
       " '\\n',\n",
       " '03:56.380 --> 04:02.380\\n',\n",
       " '인품만 받는 게 아니라 이미지나 텍스트나 뭐 그래프 같은 복잡한 형태의 데이터를 입력받을 수 있는 형태로\\n',\n",
       " '인풋만 받는 게 아니라 이미지나 텍스트나 뭐 그래프 같은 복잡한 형태의 데이터를 입력받을 수 있는 형태로\\n',\n",
       " '\\n',\n",
       " '04:02.380 --> 04:05.380\\n',\n",
       " '인공 시그마가 상당히 복잡한 형태로 발전하기 시작했습니다.\\n',\n",
       " '인공 신경망이 상당히 복잡한 형태로 발전하기 시작했습니다.\\n',\n",
       " '\\n',\n",
       " '04:05.380 --> 04:12.380\\n',\n",
       " '그런데 이번 그 한 시간의 이 수업, 하나의 수업에서 다룰 내용은\\n',\n",
       " '\\n',\n",
       " '04:12.380 --> 04:15.380\\n',\n",
       " '이 딥러닝에서 이야기하는 최근의 어떤 발전사가 아니고요.\\n',\n",
       " '\\n',\n",
       " '04:15.380 --> 04:21.380\\n',\n",
       " '좀 더 전통적인 심리에서의 인공 시그마, artificial neural network에 대한 이야기를 좀 다룰 예정입니다.\\n',\n",
       " '좀 더 전통적인 심리에서의 인공 신경망, artificial neural network에 대한 이야기를 좀 다룰 예정입니다.\\n',\n",
       " '\\n',\n",
       " '04:21.380 --> 04:25.380\\n',\n",
       " '그래서 만약에 이 딥러닝이란 어떤 트렌드로서,\\n',\n",
       " '\\n',\n",
       " '04:26.380 --> 04:30.380\\n',\n",
       " '연구가 이뤄지고 있는 최근의 어떤 연구 방향들에 관심이 있으시면,\\n',\n",
       " '\\n',\n",
       " '04:30.380 --> 04:36.380\\n',\n",
       " '제가 강의하는 수업 중에는 Running from Big Data라는 대학원 수업에 대한 자료가 있고요.\\n',\n",
       " '\\n',\n",
       " '04:36.380 --> 04:44.380\\n',\n",
       " '그리고 사실 제 자료도 있지만, 요즘은 인터넷의 웹상에 상당히 좋은 강의 자료들이 많이 있습니다.\\n',\n",
       " '\\n',\n",
       " '04:44.380 --> 04:51.380\\n',\n",
       " '딥러닝 측면만 봐도 스탠포드나 MIT 같은 유명한 대학들에서 올린 강의들이 있는데,\\n',\n",
       " '\\n',\n",
       " '04:51.380 --> 04:55.380\\n',\n",
       " '사실 제가 생각하기에는 제 강의보다 100배는 나은 강의들일 것 같습니다.\\n',\n",
       " '\\n',\n",
       " '04:56.380 --> 04:59.380\\n',\n",
       " '그래서 이 딥러닝을 보시는 것도 상당히 도움이 되지 않을까라는 생각이 듭니다.\\n',\n",
       " '그래서 이런 딥러닝 강의들을 보시는 것도 상당히 도움이 되지 않을까라는 생각이 듭니다.\\n',\n",
       " '\\n',\n",
       " '04:59.380 --> 05:02.380\\n',\n",
       " '그래서 여러분들이 다양한 자유들을 보고요.\\n',\n",
       " '그래서 여러분들이 다양한 자료들을 보고요.\\n',\n",
       " '\\n',\n",
       " '05:02.380 --> 05:07.380\\n',\n",
       " '다양한 강의 노트들을 보고, 그리고 웹에 공개된 강의가 있다면 그런 걸 보면서\\n',\n",
       " '\\n',\n",
       " '05:07.380 --> 05:15.380\\n',\n",
       " '여러분 개개인에게 조금 더 맞는, 여러분들이 조금 더 쉽게 이해할 수 있는 이런 것들을 선택해서 또 공부해보면 또 좋지 않을까라는 생각이 듭니다.\\n',\n",
       " '\\n',\n",
       " '05:15.380 --> 05:19.380\\n',\n",
       " '그래서 오늘 수업은 다시 강조하면 이 딥러닝에 대한 어떤 최근의 트렌드를 다루는 게 아니라,\\n',\n",
       " '\\n',\n",
       " '05:19.380 --> 05:24.380\\n',\n",
       " '인공 시그마가 좀 기초적인 내용들에서 다루는 부분이라고 생각하면 되겠습니다.\\n',\n",
       " '인공 신경망의 좀 기초적인 내용들에서 다루는 부분이라고 생각하면 되겠습니다.\\n',\n",
       " '\\n',\n",
       " '05:24.380 --> 05:26.380\\n',\n",
       " '그래서 이 인공 시그마가 대표적인 구조인,\\n',\n",
       " '그래서 이 인공 신경망의 대표적인 구조인,\\n',\n",
       " '\\n',\n",
       " '05:26.380 --> 05:33.380\\n',\n",
       " '멀티 레이어 퍼셉트로 또는 피드 포워드 뉴럴렉터라고 부르는 이 구조들에 대해서 우리가 다루게 될 예정이고요.\\n',\n",
       " '멀티 레이어 퍼셉트론 또는 피드 포워드 뉴럴네트워크라고 부르는 이 구조들에 대해서 우리가 다루게 될 예정이고요.\\n',\n",
       " '\\n',\n",
       " '05:33.380 --> 05:40.380\\n',\n",
       " '그래서 이게 클래스피케이션, 그리고 리그레이션에 어떻게 적용이 될 수 있을지라는 부분에 대해서 짚어볼 예정입니다.\\n',\n",
       " '그래서 이게 클래시피케이션, 그리고 리그레이션에 어떻게 적용이 될 수 있을지라는 부분에 대해서 짚어볼 예정입니다.\\n',\n",
       " '\\n',\n",
       " '05:40.380 --> 05:46.380\\n',\n",
       " '여기에서 이제 조금 더 모델을 발전시키고 심화시켜서 우리가 최근에 사용되는 딥러닝의 어떤,\\n',\n",
       " '\\n',\n",
       " '05:46.380 --> 05:52.380\\n',\n",
       " '딥러닝에서 이야기하는 복잡한 모델을 구현하는 어떤 기초로 우리가 생각을 해볼 수도 있겠습니다.\\n',\n",
       " '\\n',\n",
       " '05:52.380 --> 05:57.380\\n',\n",
       " '네, 그래서 멀티 레이어 퍼셉트론을 보면요.\\n',\n",
       " '\\n',\n",
       " '05:57.380 --> 06:01.380\\n',\n",
       " '말 그대로 여러 개의 레이어로 구성되어 있는 어떤 인공 시그마 구조입니다.\\n',\n",
       " '말 그대로 여러 개의 레이어로 구성되어 있는 어떤 인공 신경망 구조입니다.\\n',\n",
       " '\\n',\n",
       " '06:01.380 --> 06:04.380\\n',\n",
       " '그래서 레이어는 크게 세 가지 종류로 나올 수 있고요.\\n',\n",
       " '그래서 레이어는 크게 세 가지 종류로 나눌 수 있고요.\\n',\n",
       " '\\n',\n",
       " '06:04.380 --> 06:07.380\\n',\n",
       " '인풋 레이어, 그러니까 우리가 데이터에 입력받는 인풋 레이어,\\n',\n",
       " '\\n',\n",
       " '06:07.380 --> 06:10.380\\n',\n",
       " '그리고 어떤 예측을 수행하는 아웃풋 레이어가 있고요.\\n',\n",
       " '\\n',\n",
       " '06:10.380 --> 06:13.380\\n',\n",
       " '그 사이에 여러 개의 히든 레이어가 존재할 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '06:13.380 --> 06:14.380\\n',\n",
       " '이게 하나도 없을 수도 있고요.\\n',\n",
       " '\\n',\n",
       " '06:14.380 --> 06:19.380\\n',\n",
       " '아니면 최근에 어떤 딥러닝에서 이야기하는 트렌드는 이 히든 레이어가 엄청나게 많다.\\n',\n",
       " '\\n',\n",
       " '06:19.380 --> 06:21.380\\n',\n",
       " '그래서 이 구조가 상당히 딥해진다라는 얘기를 합니다.\\n',\n",
       " '\\n',\n",
       " '06:22.380 --> 06:25.380\\n',\n",
       " '어쨌든 뭐 이렇게 세 가지의 레이어 구조가 있고요.\\n',\n",
       " '\\n',\n",
       " '06:25.380 --> 06:28.380\\n',\n",
       " '그래서 이게 어떤 식으로 표현이 되냐라고 했을 때\\n',\n",
       " '\\n',\n",
       " '06:28.380 --> 06:33.380\\n',\n",
       " '인풋 레이어에 대해서 이 인풋 값들을 단계 단계로 처리한다.\\n',\n",
       " '\\n',\n",
       " '06:33.380 --> 06:37.380\\n',\n",
       " '어떤 수리적인 변형을 통해서 우리가 단계 단계로 처리를 해 나가면서\\n',\n",
       " '\\n',\n",
       " '06:37.380 --> 06:41.380\\n',\n",
       " '이 아웃풋 레이어를 통해서 최종적으로 예측 값을 얻겠다.\\n',\n",
       " '\\n',\n",
       " '06:41.380 --> 06:45.380\\n',\n",
       " '그래서 다음과 같은 식으로 우리가 레이어들의 관계를 표현해 볼 수 있습니다.\\n',\n",
       " '\\n',\n",
       " '06:45.380 --> 06:48.380\\n',\n",
       " '인풋이 있으면 첫 번째 히든 레이어, 두 번째 히든 레이어 계속해서\\n',\n",
       " '\\n',\n",
       " '06:48.380 --> 06:51.380\\n',\n",
       " '그리고 마지막 아웃풋 레이어 이런 식으로 표현할 수 있고\\n',\n",
       " '\\n',\n",
       " '06:51.380 --> 06:52.380\\n',\n",
       " '이런 어떤 관계를\\n',\n",
       " '\\n',\n",
       " '06:52.380 --> 06:55.380\\n',\n",
       " '우리가 다음과 같이 이제 표현해 볼 수 있습니다.\\n',\n",
       " '\\n',\n",
       " '06:55.380 --> 06:56.380\\n',\n",
       " '인풋 레이어가 있고요.\\n',\n",
       " '\\n',\n",
       " '06:56.380 --> 07:00.380\\n',\n",
       " '여기서 바로 얘네들의 적당한 컴비네이션을 아웃풋으로 얻는다라고 한다면\\n',\n",
       " '\\n',\n",
       " '07:00.380 --> 07:03.380\\n',\n",
       " '얘는 단순히 히든 레이어가 없는 형태가 되겠죠.\\n',\n",
       " '\\n',\n",
       " '07:03.380 --> 07:07.380\\n',\n",
       " '이건 사실 우리가 돌이켜보면 리니어 리그레션 또는 로지스트 리그레션과\\n',\n",
       " '\\n',\n",
       " '07:07.380 --> 07:10.380\\n',\n",
       " '같은 형태로 우리가 이해해 볼 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '07:10.380 --> 07:13.380\\n',\n",
       " '히든 레이어 하나 추가해서 한 번 처리하는데\\n',\n",
       " '\\n',\n",
       " '07:13.380 --> 07:16.380\\n',\n",
       " '여러 유닛으로 처리를 한 다음에\\n',\n",
       " '\\n',\n",
       " '07:16.380 --> 07:19.380\\n',\n",
       " '이 처리된 각각의 유닛들을 결합해서 최종 아웃풋을 얻자.\\n',\n",
       " '\\n',\n",
       " '07:19.380 --> 07:21.380\\n',\n",
       " '이런 히든 레이어를 여러 개 가진 형태로\\n',\n",
       " '\\n',\n",
       " '07:21.380 --> 07:24.380\\n',\n",
       " '생각해 볼 수가 있겠죠.\\n',\n",
       " '\\n',\n",
       " '07:24.380 --> 07:26.380\\n',\n",
       " '그래서 모델 아키텍처를 다시 한 번 정리해 보면\\n',\n",
       " '\\n',\n",
       " '07:26.380 --> 07:29.380\\n',\n",
       " '인풋 레이어, 히든 레이어, 아웃풋 레이어가 있다.\\n',\n",
       " '\\n',\n",
       " '07:29.380 --> 07:33.380\\n',\n",
       " '그리고 이 각각의 인풋 레이어의 경우는\\n',\n",
       " '\\n',\n",
       " '07:33.380 --> 07:38.380\\n',\n",
       " '각각의 유닛들이 어떤 하나의 인풋 피처의 각과 대응이 된다.\\n',\n",
       " '각각의 유닛들이 어떤 하나의 인풋 피처의 값과 대응이 된다.\\n',\n",
       " '\\n',\n",
       " '07:38.380 --> 07:42.380\\n',\n",
       " '그러면 이 인풋 피처들을 적당히 결합해서 히든 레이어의 유닛들을 값으로 얻는데\\n',\n",
       " '\\n',\n",
       " '07:42.380 --> 07:45.380\\n',\n",
       " '이 결합하는 과정의 이 커넥션들\\n',\n",
       " '\\n',\n",
       " '07:45.380 --> 07:48.380\\n',\n",
       " '이 각각이 하나의 파라미터 각과 대응이 된다.\\n',\n",
       " '이 각각이 하나의 파라미터 값과 대응이 된다.\\n',\n",
       " '\\n',\n",
       " '07:48.380 --> 07:50.380\\n',\n",
       " '그래서 이 파라미터가 여기에\\n',\n",
       " '\\n',\n",
       " '07:50.380 --> 07:52.380\\n',\n",
       " '이 커넥션들이 존재하고요.\\n',\n",
       " '\\n',\n",
       " '07:52.380 --> 07:54.380\\n',\n",
       " '이 파라미터들을 결국 우리가\\n',\n",
       " '\\n',\n",
       " '07:54.380 --> 07:57.380\\n',\n",
       " '값들을 데이터로부터 우리가 학습하고 싶은 거죠.\\n',\n",
       " '\\n',\n",
       " '07:57.380 --> 07:58.380\\n',\n",
       " '어떤 식으로 학습하냐?\\n',\n",
       " '\\n',\n",
       " '07:58.380 --> 08:00.380\\n',\n",
       " '이 입력이 얻어졌을 때 이 출력이\\n',\n",
       " '\\n',\n",
       " '08:00.380 --> 08:03.380\\n',\n",
       " '실제 y와 최대한 가까워지도록 우리가\\n',\n",
       " '\\n',\n",
       " '08:03.380 --> 08:05.380\\n',\n",
       " '학습을 시키고 싶겠다라는 게\\n',\n",
       " '\\n',\n",
       " '08:05.380 --> 08:08.380\\n',\n",
       " '우리가 지도학습에서 가진 기본 목표이기 때문에\\n',\n",
       " '\\n',\n",
       " '08:08.380 --> 08:10.380\\n',\n",
       " '그런 식으로 파라미터를 얻겠다라고\\n',\n",
       " '\\n',\n",
       " '08:10.380 --> 08:14.380\\n',\n",
       " '우리가 생각을 해 볼 수가 있을 것 같습니다.\\n',\n",
       " '\\n',\n",
       " '08:14.380 --> 08:17.380\\n',\n",
       " '그래서 이 모델 아키텍처에 대한 얘기했는데\\n',\n",
       " '\\n',\n",
       " '08:17.380 --> 08:19.380\\n',\n",
       " '근데 히든 레이어에 대한 부분을 좀 짚어 보거든요.\\n',\n",
       " '근데 히든 레이어에 대한 부분을 좀 짚어 보면요.\\n',\n",
       " '\\n',\n",
       " '08:20.380 --> 08:22.380\\n',\n",
       " '일단 히든 레이어\\n',\n",
       " '\\n',\n",
       " '08:22.380 --> 08:24.380\\n',\n",
       " '히든 레이어의 가장 중요한 거는요.\\n',\n",
       " '\\n',\n",
       " '08:24.380 --> 08:26.380\\n',\n",
       " '우리가 어떻게 논리니어한 변화를 해주냐 입니다.\\n',\n",
       " '\\n',\n",
       " '08:26.380 --> 08:30.380\\n',\n",
       " '어떤 식으로 논리니어 변화를 해줄 건가가 핵심이 되겠습니다.\\n',\n",
       " '\\n',\n",
       " '08:30.380 --> 08:33.380\\n',\n",
       " '근데 왜 논리니얼리티인가?\\n',\n",
       " '\\n',\n",
       " '08:33.380 --> 08:35.380\\n',\n",
       " '생각해 보면요.\\n',\n",
       " '\\n',\n",
       " '08:35.380 --> 08:37.380\\n',\n",
       " '우리가 레이어 여러 개 쌓을 수가 있어요.\\n',\n",
       " '\\n',\n",
       " '08:37.380 --> 08:42.380\\n',\n",
       " '그런데 이 변환들이 단순히 리니어 변환이다.\\n',\n",
       " '\\n',\n",
       " '08:42.380 --> 08:44.380\\n',\n",
       " '리니어 트랜스포메이션이다.\\n',\n",
       " '\\n',\n",
       " '08:44.380 --> 08:47.380\\n',\n",
       " '그럼 리니어 트랜스포메이션은 계속해서 쌓아 나가는 거죠.\\n',\n",
       " '\\n',\n",
       " '08:47.380 --> 08:49.380\\n',\n",
       " '리니어 트랜스포메이션의 리니어 트랜스포메이션은\\n',\n",
       " '\\n',\n",
       " '08:50.380 --> 08:52.380\\n',\n",
       " '그냥 리니어 트랜스포메이션입니다.\\n',\n",
       " '\\n',\n",
       " '08:52.380 --> 08:55.380\\n',\n",
       " '그래서 계속해서 리니어 트랜스포메이션 해봤자\\n',\n",
       " '\\n',\n",
       " '08:55.380 --> 09:00.380\\n',\n",
       " '이렇게 해봤자 그냥 단순히 하나의 리니어 모델이랑 다르지 않는다.\\n',\n",
       " '\\n',\n",
       " '09:00.380 --> 09:03.380\\n',\n",
       " '레이어를 여러 개 쌓는 게 아무런 의미가 없어진다.\\n',\n",
       " '\\n',\n",
       " '09:03.380 --> 09:05.380\\n',\n",
       " '라는 부분에 문제점이 있습니다.\\n',\n",
       " '\\n',\n",
       " '09:05.380 --> 09:06.380\\n',\n",
       " '그래서\\n',\n",
       " '\\n',\n",
       " 'WEBVTT\\n',\n",
       " '\\n',\n",
       " '00:00.000 --> 00:09.760\\n',\n",
       " '각 히든 레이어에 어떻게 논리니얼리티를 적절히 부여하냐가 상당히 중요한 이슈가 될 수 있습니다.\\n',\n",
       " '\\n',\n",
       " '00:09.760 --> 00:14.880\\n',\n",
       " '히든 레이어들이 어떻게 작동하냐를 보면 다음과 같습니다.\\n',\n",
       " '그래서 히든 레이어들이 어떻게 작동하냐를 보면 다음과 같이 작동합니다.\\n',\n",
       " '\\n',\n",
       " '00:14.880 --> 00:19.920\\n',\n",
       " '첫 번째 히든 레이어는 인풋을 받아서 얘를 먼저 리니어 트랜스포메이션으로 다음과 같습니다.\\n',\n",
       " '첫 번째 히든 레이어는 인풋을 받아서 얘를 먼저 리니어 트랜스포메이션으로 다음과 같습니다.\\n',\n",
       " '\\n',\n",
       " '00:19.920 --> 00:26.240\\n',\n",
       " '얘네들이 파라미터가 되겠죠. 이 파라미터들을 이용해서 어떤 벡터를 얻고요.\\n',\n",
       " '\\n',\n",
       " '00:26.240 --> 00:30.640\\n',\n",
       " '그래서 이 벡터의 차원은 해당 히든 레이어 유닛과 같습니다.\\n',\n",
       " '그래서 이 벡터의 차원은 해당 히든 레이어 유닛과 같습니다.\\n',\n",
       " '\\n',\n",
       " '00:30.640 --> 00:37.840\\n',\n",
       " '그래서 이 벡터를 우선 얻고요. 그 다음에 어떤 논리니어 펑션을 사용해서 논리니어 트랜스포메이션을 합니다.\\n',\n",
       " '\\n',\n",
       " '00:37.840 --> 00:42.160\\n',\n",
       " '이게 없으면 유얼렛의 레이어를 쌓는 의미가 없어지고요.\\n',\n",
       " '이게 없으면 뉴럴네트워크의 레이어를 쌓는 의미가 없어지고요.\\n',\n",
       " '\\n',\n",
       " '00:42.160 --> 00:45.840\\n',\n",
       " '이걸 잘 하는 게 중요합니다. 어쨌든 어떤 논리니어 펑션을 사용하면 되고요.\\n',\n",
       " '\\n',\n",
       " '00:45.840 --> 00:51.040\\n',\n",
       " '이거를 각 히든 레이어마다 비슷한 방식으로 계속해서 논리니어 변환들을 쌓아갑니다.\\n',\n",
       " '이거를 각 히든 레이어마다 비슷한 방식으로 계속해서 논리니어 변환들을 쌓아나갑니다.\\n',\n",
       " '\\n',\n",
       " '00:51.040 --> 00:56.160\\n',\n",
       " '그래서 이렇게 함으로써 히든 레이어가 쌓이면 쌓일수록 이 모델이 상당히 복잡해질 수가 있는데요.\\n',\n",
       " '\\n',\n",
       " '00:56.160 --> 00:56.200\\n',\n",
       " '그래서 이렇게 함으로써 히든 레이어가 쌓이면 쌓일수록 이 모델이 상당히 복잡해질 수가 있는데요.\\n',\n",
       " '\\n',\n",
       " '00:56.200 --> 01:06.200\\n',\n",
       " '그래서 어떤 복잡한 형태의 어떤 입력과 출력 간의 관계를 더 설명할 수 있겠다라는 정도로 우리가 이해를 해볼 수가 있을 것 같습니다.\\n',\n",
       " '\\n',\n",
       " '01:06.200 --> 01:12.600\\n',\n",
       " '그 다음에 이런 계속 히든 유닛들을 다 계산한 다음에요.\\n',\n",
       " '\\n',\n",
       " '01:12.600 --> 01:19.400\\n',\n",
       " '그 다음에 이제 논리니어 액티베이션 각각 히든 유닛에서 논리니어 액티베이션 펑션을 쓰면 되는 건데\\n',\n",
       " '\\n',\n",
       " '01:19.400 --> 01:23.800\\n',\n",
       " '근데 어떤 논리니어 액티베이션 펑션들을 쓸 수 있을까를 생각해보면요.\\n',\n",
       " '\\n',\n",
       " '01:23.800 --> 01:26.120\\n',\n",
       " '상당히 다양한 펑션들을 우리가 고민해볼 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '01:26.120 --> 01:30.760\\n',\n",
       " '근데 가장 흔히 쓰이는 건 이 두 가지입니다.\\n',\n",
       " '\\n',\n",
       " '01:30.760 --> 01:36.120\\n',\n",
       " '이 렐루, 렉티파잉 논리니어 유닛이라고 불리는 렐루.\\n',\n",
       " '\\n',\n",
       " '01:36.120 --> 01:46.480\\n',\n",
       " '그리고 또 하이퍼블릭 탄젠트, 텐에이치 펑션 이 두 가지가 주로 많이 쓰이는 액티베이션 펑션의 종류입니다.\\n',\n",
       " '\\n',\n",
       " '01:46.480 --> 01:52.920\\n',\n",
       " '그래서 얘네들이 어떤 식으로 각각 값을 입력 받았을 때 어떤 식으로 값을 주는지를 보면요.\\n',\n",
       " '\\n',\n",
       " '01:52.920 --> 01:56.040\\n',\n",
       " '텐에이치 같은 경우는 어떤 입력을 받았을 때 이 값을\\n',\n",
       " '\\n',\n",
       " '01:56.040 --> 02:00.040\\n',\n",
       " '마이너스 2부터 1까지의 사이 값으로 변환시켜주는 역할을 합니다.\\n',\n",
       " '마이너스 1부터 1까지의 사이 값으로 변환시켜주는 역할을 합니다.\\n',\n",
       " '\\n',\n",
       " '02:00.040 --> 02:06.600\\n',\n",
       " '그래서 인풋이 아주 작은 음수일 땐 텐에이치의 값은 텐에이치 함수 값은 마이너스 1에 가까워지겠고요.\\n',\n",
       " '\\n',\n",
       " '02:06.600 --> 02:16.440\\n',\n",
       " 'X가 입력이 아주 큰 수일 때는 텐에이치 값이 1에 아주 가까운 식으로 수렴하게 되는 걸 우리가 알 수가 있고요.\\n',\n",
       " '\\n',\n",
       " '02:16.440 --> 02:22.120\\n',\n",
       " '그리고 이제 렐루, 렐루 같은 경우는 입력이 0보다 작으면 0을 주고요.\\n',\n",
       " '\\n',\n",
       " '02:22.120 --> 02:25.480\\n',\n",
       " '입력이 0보다 크면 그 값을 그대로 출력해주는\\n',\n",
       " '\\n',\n",
       " '02:25.480 --> 02:27.080\\n',\n",
       " '성질을 가집니다.\\n',\n",
       " '\\n',\n",
       " '02:27.080 --> 02:31.400\\n',\n",
       " '전통적으로는 이 하이퍼블릭 탄젠트가 가장 많이 쓰여왔고요.\\n',\n",
       " '\\n',\n",
       " '02:31.400 --> 02:37.640\\n',\n",
       " '널리 쓰여왔는데 최근에는 렐루, 렐루와 렐루를 조금 변환시킨 형태의 것들이 많이 쓰이고 있습니다.\\n',\n",
       " '\\n',\n",
       " '02:37.640 --> 02:41.800\\n',\n",
       " '그런데 이게 어떤 게 그럼 더 좋을까요? 라고 하면은 이거는 사실 하이퍼 플라미터입니다.\\n',\n",
       " '그런데 이게 어떤 게 그럼 더 좋을까요? 라고 하면은 이거는 사실 하이퍼 파라미터입니다.\\n',\n",
       " '\\n',\n",
       " '02:41.800 --> 02:47.080\\n',\n",
       " '그 말인즉슨 우리가 주어진 데이터셋에 어쨌든 맞게 선택을 잘 해야 되는 문제고요.\\n',\n",
       " '\\n',\n",
       " '02:47.080 --> 02:49.640\\n',\n",
       " '이게 뭐가 무조건 좋다 라는 건 없다.\\n',\n",
       " '\\n',\n",
       " '02:49.640 --> 02:54.360\\n',\n",
       " '우리가 주어진 데이터셋에 대해 가장 좋은 액티베이션 펑션을 잘 선택하면 되는 이슈다.\\n',\n",
       " '\\n',\n",
       " '02:54.360 --> 02:55.320\\n',\n",
       " '이 선택의 이슈다.\\n',\n",
       " '\\n',\n",
       " '02:55.480 --> 03:01.160\\n',\n",
       " '라는 걸 우리가 좀 짚고 넘어갈 필요가 있겠습니다.\\n',\n",
       " '\\n',\n",
       " '03:01.160 --> 03:03.160\\n',\n",
       " '그 다음에 아플 레이어입니다.\\n',\n",
       " '그 다음에 아웃풋 레이어입니다.\\n',\n",
       " '\\n',\n",
       " '03:03.160 --> 03:09.960\\n',\n",
       " '아플 레이어는 가장 마지막 히든 레이어의 어떤 결과물들을 잘 변형시켜서 결합해서\\n',\n",
       " '아웃풋 레이어는 가장 마지막 히든 레이어의 어떤 결과물들을 잘 변형시켜서 결합해서\\n',\n",
       " '\\n',\n",
       " '03:09.960 --> 03:13.240\\n',\n",
       " '우리가 그 최종적인 예측 결과를 얻겠다.\\n',\n",
       " '\\n',\n",
       " '03:13.240 --> 03:17.640\\n',\n",
       " '이 레이블 y에 대한 예측 값을 얻겠다. 라고 생각하면 될 것 같습니다.\\n',\n",
       " '\\n',\n",
       " '03:17.640 --> 03:24.360\\n',\n",
       " '그래서 목표와 타스크에 대해서 예측을 만드는 레이어라고 우리가 정리를 해볼 수가 있겠습니다.\\n',\n",
       " '\\n',\n",
       " '03:24.360 --> 03:25.320\\n',\n",
       " '그래서 우리가\\n',\n",
       " '\\n',\n",
       " '03:25.320 --> 03:30.360\\n',\n",
       " '대표적으로 다양한 형태의 어떤 아플 레이어의 어떤 형태를 생각해 볼 수 있는데요.\\n',\n",
       " '대표적으로 다양한 형태의 어떤 아웃풋 레이어의 어떤 형태를 생각해 볼 수 있는데요.\\n',\n",
       " '\\n',\n",
       " '03:30.360 --> 03:36.120\\n',\n",
       " '첫 번째는 리니어한 어떤 아플을 생각해 볼 수 있습니다.\\n',\n",
       " '첫 번째는 리니어한 어떤 아웃풋을 생각해 볼 수 있습니다.\\n',\n",
       " '\\n',\n",
       " '03:36.120 --> 03:38.920\\n',\n",
       " '리니어 액티베이션을 사용할 수도 있고요.\\n',\n",
       " '\\n',\n",
       " '03:38.920 --> 03:41.400\\n',\n",
       " '리니어 액티베이션을 사용한다는 뜻은요.\\n',\n",
       " '\\n',\n",
       " '03:41.400 --> 03:48.280\\n',\n",
       " '우리가 다음과 같이 이제 마지막 히든 레이어의 아플에 리니어 컴비네이션을 잘 해 가지고\\n',\n",
       " '우리가 다음과 같이 이제 마지막 히든 레이어의 아웃풋에 리니어 컴비네이션을 잘 해 가지고\\n',\n",
       " '\\n',\n",
       " '03:48.280 --> 03:51.480\\n',\n",
       " '우리가 최종 예측 값을 얻겠다.\\n',\n",
       " '\\n',\n",
       " '03:51.480 --> 03:55.160\\n',\n",
       " '그래서 뭐 이런 식으로 다 리니어 레이어층과 비슷한 아이디어겠죠.\\n',\n",
       " '그래서 뭐 이런 식으로 다 리니어 리그레션과 비슷한 아이디어겠죠.\\n',\n",
       " '\\n',\n",
       " '03:55.320 --> 04:01.160\\n',\n",
       " '또는 시그믈드 펑션 여기다 시그믈드 펑션이 쓰여 가지고 우리가 예측 값을 얻겠다.\\n',\n",
       " '또는 시그모이드 펑션 여기다 시그모이드 펑션이 쓰여 가지고 우리가 예측 값을 얻겠다.\\n',\n",
       " '\\n',\n",
       " '04:01.160 --> 04:04.040\\n',\n",
       " '그러면 y 값이 0부터 1 사이의 값을 가지겠죠.\\n',\n",
       " '\\n',\n",
       " '04:04.040 --> 04:10.120\\n',\n",
       " '그래서 0에 가까울수록 클래스 0으로 분류하고 1에 가까울수록 클래스 1로 분류하고 이런 걸 생각할 수가 있을 겁니다.\\n',\n",
       " '\\n',\n",
       " '04:10.120 --> 04:13.400\\n',\n",
       " '소프트맥스의 경우 멀티 클래스의 경우는 이걸 좀 확장시키는데요.\\n',\n",
       " '\\n',\n",
       " '04:13.400 --> 04:16.440\\n',\n",
       " '이게 멀티노멜 로지스 리에이션의 아이디어와 같습니다.\\n',\n",
       " '이게 멀티노미얼 로지스틱 리그레션의 아이디어와 같습니다.\\n',\n",
       " '\\n',\n",
       " '04:16.440 --> 04:21.960\\n',\n",
       " '그래서 우리가 예측 값을 다음 식으로 표현을 한다고 했을 때요.\\n',\n",
       " '\\n',\n",
       " '04:21.960 --> 04:23.160\\n',\n",
       " '우리가 클래스가 c 개라면 c 개의 어떤 값들을 얻을 건데요.\\n',\n",
       " '\\n',\n",
       " '04:23.160 --> 04:23.320\\n',\n",
       " '우리가 클래스가 c 개라면 c 개의 어떤 값들을 얻을 건데요.\\n',\n",
       " '\\n',\n",
       " '04:23.320 --> 04:25.480\\n',\n",
       " '우리가 클래스가 c 개라면 c 개의 어떤 값들을 얻을 건데요.\\n',\n",
       " '\\n',\n",
       " '04:25.480 --> 04:30.440\\n',\n",
       " '각 c 개는 해당 클래스에 대한 속할 확률의 근사로 생각할 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '04:30.440 --> 04:38.040\\n',\n",
       " '그래서 먼저 다음과 같이 선형 변환을 통해서 g 값을 얻은 다음에 얘네들의 다음과 같이 변형을 시켜 주는데요.\\n',\n",
       " '그래서 먼저 다음과 같이 선형 변환을 통해서 g 값을 얻은 다음에 얘네들의 다음과 같이 변형을 시켜 주는데요.\\n',\n",
       " '\\n',\n",
       " '04:38.040 --> 04:43.960\\n',\n",
       " '이 변형은 그냥 이런 수식어로 하면 된다고 보면 되는데 이게 무슨 의미가 있나 를 보면요.\\n',\n",
       " '이 변형은 그냥 이런 수식으로 하면 된다고 보면 되는데 이게 무슨 의미가 있나 를 보면요.\\n',\n",
       " '\\n',\n",
       " '04:43.960 --> 04:52.840\\n',\n",
       " '이 y1부터 yk까지가 y, i는 다 0보다 크거나 같아지면서 얘네들의 합은 1이 되도록 변형이 됩니다.\\n',\n",
       " '\\n',\n",
       " '04:52.840 --> 04:53.160\\n',\n",
       " '그래서 c 값이 0으로 변형이 됩니다.\\n',\n",
       " '\\n',\n",
       " '04:53.160 --> 05:07.880\\n',\n",
       " '그래서 이런 조건을 만족하게 해주는 소프트 맥스 레이어를 소프트 맥스 액티베이션을 우리가 사용해서 우리가 다음과 같이 아웃풀 레이어를 구성해 볼 수가 있습니다.\\n',\n",
       " '그래서 이런 조건을 만족하게 해주는 소프트 맥스 레이어를 소프트 맥스 액티베이션을 우리가 사용해서 우리가 다음과 같이 아웃풋 레이어를 구성해 볼 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '05:07.880 --> 05:16.440\\n',\n",
       " '그래서 앞에서는 우리가 인공 신경망이라는 구조를 어떻게 설계할지 멀티레어 펄세트론의 국한에서 이 구조를 어떻게 설계할지에 대한 이야기를 다뤄봤고요.\\n',\n",
       " '그래서 앞에서는 우리가 인공 신경망이라는 구조를 어떻게 설계할지 멀티레어 펄셉트론에 국한해서 이 구조를 어떻게 설계할지에 대한 이야기를 다뤄봤고요.\\n',\n",
       " '\\n',\n",
       " '05:16.440 --> 05:18.040\\n',\n",
       " '상당히 단순한 내용이긴 합니다.\\n',\n",
       " '\\n',\n",
       " '05:18.040 --> 05:21.800\\n',\n",
       " '그냥 여러 개의 레이어를 쌓는데 그 레이어를 쌓는다는 게 어떤 의미이고요.\\n',\n",
       " '\\n',\n",
       " '05:21.800 --> 05:22.040\\n',\n",
       " '각 레이어, 히든 레이어에서 우리가 구성한 레이어를 구성하는 게 어떤 의미이고요.\\n',\n",
       " '\\n',\n",
       " '05:22.040 --> 05:22.680\\n',\n",
       " '각 레이어, 히든 레이어에서 우리가 구성한 레이어를 구성하는 게 어떤 의미이고요.\\n',\n",
       " '\\n',\n",
       " '05:22.680 --> 05:30.760\\n',\n",
       " '히든 레이어에서 우리가 논리니어한 액티베이션 펑션을 사용해서 잘 논리니어한 티를 주입해줘야 우리가 이 레이어를 쌓는 게 의미가 있어진다.\\n',\n",
       " '히든 레이어에서 우리가 논리니어한 액티베이션 펑션을 사용해서 잘 논리니얼리티를 주입해줘야 우리가 이 레이어를 쌓는 게 의미가 있어진다.\\n',\n",
       " '\\n',\n",
       " '05:30.760 --> 05:39.160\\n',\n",
       " '그리고 아웃풀 레이어는 우리가 원하는 예측의 값을 얻을 수 있는 형태로 설정해 주면 된다 정도의 얘기를 했습니다.\\n',\n",
       " '그리고 아웃풋 레이어는 우리가 원하는 예측의 값을 얻을 수 있는 형태로 설정해 주면 된다 정도의 얘기를 했습니다.\\n',\n",
       " '\\n',\n",
       " '05:39.160 --> 05:41.160\\n',\n",
       " '이제는 이 모델을 어떻게 학습시킬 것인가.\\n',\n",
       " '\\n',\n",
       " '05:41.160 --> 05:45.400\\n',\n",
       " '그러니까 이 모델의 파라미터 값을 어떻게 결정할 것인가 라는 부분인데요.\\n',\n",
       " '\\n',\n",
       " '05:45.400 --> 05:48.840\\n',\n",
       " '이걸 고민할 때 먼저 학습 데이터가 주어진 상황에서 이야기하겠죠.\\n',\n",
       " '\\n',\n",
       " '05:48.840 --> 05:52.200\\n',\n",
       " '학습 데이터가 다음과 같이 n개의 데이터 포인트 구성이 되어 있다.\\n',\n",
       " '\\n',\n",
       " '05:52.200 --> 05:54.920\\n',\n",
       " '매번 그려놨듯이 이렇게 간주하겠습니다.\\n',\n",
       " '매번 그래왔듯이 이렇게 간주하겠습니다.\\n',\n",
       " '\\n',\n",
       " '05:54.920 --> 06:02.440\\n',\n",
       " '그래서 각 인풋 데이터 포인트들은, 인풋 벡터들은 다음과 같이 d개의 Feature 값으로 구성이 되어 있고요.\\n',\n",
       " '\\n',\n",
       " '06:02.440 --> 06:05.000\\n',\n",
       " '그리고 거기에 대한 대응되는 레이블이 주어져 있다.\\n',\n",
       " '그리고 거기에 대응되는 레이블이 주어져 있다.\\n',\n",
       " '\\n',\n",
       " '06:05.000 --> 06:09.160\\n',\n",
       " '이 레이블이 실수형일 수도 있고, Regression 문제라면 실수형이 주어질 테고,\\n',\n",
       " '\\n',\n",
       " '06:09.160 --> 06:12.760\\n',\n",
       " '아니면 뭐 Binary Classification이라면 0 또는 1의 값을 가질 테고,\\n',\n",
       " '\\n',\n",
       " '06:12.760 --> 06:17.560\\n',\n",
       " '멀티 클래스라면 그 클래스 정보를 가지고 있겠죠.\\n',\n",
       " '\\n',\n",
       " '06:17.560 --> 06:20.840\\n',\n",
       " '어쨌든 우리가 얻고자 하는 모델은 다음과 같이 이제 적어볼 수 있을 테고요.\\n',\n",
       " '\\n',\n",
       " '06:20.840 --> 06:27.880\\n',\n",
       " '근데 우리가 이 Cost Function, 우리가 학습을 위해서 다음과 같은 어떤 수식을 정의할 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '06:27.880 --> 06:32.360\\n',\n",
       " '그러니까 이게 뭐냐면, Linear Regression과 Logistic Regression을 했던 것과 다르지 않습니다.\\n',\n",
       " '\\n',\n",
       " '06:32.360 --> 06:39.320\\n',\n",
       " 'Cost Function은 이 각 데이터 포인트, 학습 데이터 포인트별로 실제 레이블과 예측된 레이블의 차이,\\n',\n",
       " '\\n',\n",
       " '06:39.320 --> 06:47.080\\n',\n",
       " 'Loss Function의 어떤 값을, 합을 줄이고 싶다라는 식으로 이해를 하시면 되겠습니다.\\n',\n",
       " '\\n',\n",
       " '06:47.080 --> 06:49.480\\n',\n",
       " '그런데 이게 이렇게 정의하면 되는데요.\\n',\n",
       " '\\n',\n",
       " '06:49.480 --> 06:49.960\\n',\n",
       " '그런데 이 와이프가 이렇게 정의하면 되는데요.\\n',\n",
       " '\\n',\n",
       " '06:49.960 --> 06:50.680\\n',\n",
       " '그런데 이 와이프가 이렇게 정의하면 되는데요.\\n',\n",
       " '\\n',\n",
       " '06:50.680 --> 06:55.800\\n',\n",
       " '이 YI가 이 함수를 통해, 이 NewElet을 통해 얻어줄 수가 있죠.\\n',\n",
       " '이 YI가 이 함수를 통해, 이 neural network를 통해 얻어질 수가 있죠.\\n',\n",
       " '\\n',\n",
       " '06:55.800 --> 06:58.360\\n',\n",
       " '그런데 여기서 좀 중요한 점은요.\\n',\n",
       " '\\n',\n",
       " '06:58.360 --> 07:03.320\\n',\n",
       " '이 Cost Function 자체가 상당히 이 세타에 대해서 너무 컴백성한 Function이다.\\n',\n",
       " '이 Cost Function 자체가 상당히 이 세타에 대해서 너무 컴팩트한 Function이다.\\n',\n",
       " '\\n',\n",
       " '07:03.320 --> 07:11.160\\n',\n",
       " '우리가 Linear Regression이나 Logistic Regression은 이 Cost Function을 미니마이즈하는 베스트 프라이미터 값을 찾는 게 상당히 쉬운 문제였습니다.\\n',\n",
       " '우리가 Linear Regression이나 Logistic Regression은 이 Cost Function을 미니마이즈하는 베스트 파라미터 값을 찾는 게 상당히 쉬운 문제였습니다.\\n',\n",
       " '\\n',\n",
       " '07:11.160 --> 07:14.120\\n',\n",
       " '그런데 여기서 NewElet에서는 그렇지가 않습니다.\\n',\n",
       " '그런데 여기서 neural network에서는 그렇지가 않습니다.\\n',\n",
       " '\\n',\n",
       " '07:14.120 --> 07:19.800\\n',\n",
       " '그게 NewElet의 어려운 점, NewElet을 사용하는 어려움 중에 하나였는데,\\n',\n",
       " '그게 neural network의 어려운 점, neural network을 사용하는 어려움 중에 하나였는데,\\n',\n",
       " '\\n',\n",
       " '07:19.800 --> 07:23.640\\n',\n",
       " '어쨌든 이거에 대해서 어떻게 우리가 해소할 수 있을까?\\n',\n",
       " '\\n',\n",
       " '07:23.640 --> 07:28.760\\n',\n",
       " '어쨌든 Gradient에 기반한 어떤 최적화 방법으로 사용할 수 있다.\\n',\n",
       " '\\n',\n",
       " '07:28.760 --> 07:33.080\\n',\n",
       " 'Logistic Regression과 마찬가지로 Gradient에 기반한 최적화 방법으로 사용하면 되는데,\\n',\n",
       " '\\n',\n",
       " '07:33.080 --> 07:38.200\\n',\n",
       " '이 과정을 우리가 이 몇 개의 레이어, 몇 개의 레이어 각각에 대한 파라미터들이 있죠.\\n',\n",
       " '이 과정을 우리가 이 여러 개의 레이어, 여러 개의 레이어 각각에 대한 파라미터들이 있죠.\\n',\n",
       " '\\n',\n",
       " '07:38.200 --> 07:42.840\\n',\n",
       " '이걸 학습시키는 과정을 우리가 Back Propagation이라고 이야기할 겁니다.\\n',\n",
       " '이걸 학습시키는 과정을 우리가 Back Propagation이라고 이야기할 겁니다.\\n',\n",
       " '\\n',\n",
       " '07:42.840 --> 07:44.920\\n',\n",
       " '가장 단순하게 생각해보면요.\\n',\n",
       " '\\n',\n",
       " '07:44.920 --> 07:46.760\\n',\n",
       " '그냥 우리가 이 연산을 하면 돼요.\\n',\n",
       " '\\n',\n",
       " '07:46.760 --> 07:47.480\\n',\n",
       " '그렇죠?\\n',\n",
       " '\\n',\n",
       " '07:47.480 --> 07:48.920\\n',\n",
       " 'Logistic Regression에서 이 식을 우리가 이해할 수 있습니다.\\n',\n",
       " 'Logistic Regression에서 이 식을 우리가 이해할 수 있습니다.\\n',\n",
       " '\\n',\n",
       " '07:48.920 --> 07:49.480\\n',\n",
       " '그렇죠?\\n',\n",
       " '\\n',\n",
       " '07:49.800 --> 07:52.120\\n',\n",
       " '그냥 이 연산을 계속해서 반복하면 됩니다.\\n',\n",
       " '\\n',\n",
       " '07:52.120 --> 07:54.280\\n',\n",
       " '그리고 이 신호 적당히 작게 잡았어요.\\n',\n",
       " '\\n',\n",
       " '07:54.280 --> 07:58.360\\n',\n",
       " '그래서 이 연산을 반복하면 되는데,\\n',\n",
       " '\\n',\n",
       " '07:58.360 --> 07:59.640\\n',\n",
       " '그래서 뭐 이렇게 하면 되겠다.\\n',\n",
       " '\\n',\n",
       " '07:59.640 --> 08:03.080\\n',\n",
       " '근데 이 loss function 부분은 어떻게 설정하면 될까?\\n',\n",
       " '\\n',\n",
       " '08:03.080 --> 08:07.560\\n',\n",
       " '먼저 그 cost function 정의하기에 loss function, error는 어떻게 선택하면 될까?\\n',\n",
       " '\\n',\n",
       " '08:07.560 --> 08:10.760\\n',\n",
       " 'Regression이라면 그냥 squared error를 일반적으로 사용할 수 있어요.\\n',\n",
       " '\\n',\n",
       " '08:10.760 --> 08:15.080\\n',\n",
       " '이게 무조건 이거랑은 아니고 일반적인, typical한 choice가 이렇습니다.\\n',\n",
       " '\\n',\n",
       " '08:15.080 --> 08:19.640\\n',\n",
       " 'Binary Classification, 우리가 Logistic Regression에서 사용했던 Binary Class Entropy.\\n',\n",
       " '\\n',\n",
       " '08:19.800 --> 08:23.240\\n',\n",
       " '그리고 멀티 클래스라면 우리가 Categorical Cross Entropy,\\n',\n",
       " '\\n',\n",
       " '08:23.240 --> 08:26.840\\n',\n",
       " '이 Binary Cross Entropy의 어떤 확장 버전으로 볼 수 있고요.\\n',\n",
       " '\\n',\n",
       " '08:26.840 --> 08:28.520\\n',\n",
       " '이런 걸 사용할 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '08:28.520 --> 08:37.480\\n',\n",
       " '얘는 사실 그 Multinomial Logistic Regression에서 사용하는 목적 함수가 되기도 합니다.\\n',\n",
       " '\\n',\n",
       " '08:37.480 --> 08:43.720\\n',\n",
       " '그래서 이렇게 어떤 loss function을 사용하면 될지 이렇게 한번 짚어볼 수가 있겠고요.\\n',\n",
       " '\\n',\n",
       " '08:43.720 --> 08:46.440\\n',\n",
       " '근데 이런 최적화식은 어디서 왔냐라고 생각해보면,\\n',\n",
       " '\\n',\n",
       " '08:46.440 --> 08:47.800\\n',\n",
       " '우리가 Logistic Regression 이야기할 때 가볍게 얘기했었는데,\\n',\n",
       " '\\n',\n",
       " '08:47.800 --> 08:48.440\\n',\n",
       " '우리가 Logistic Regression을 이야기할 때 가볍게 이야기했었는데,\\n',\n",
       " '\\n',\n",
       " '08:48.440 --> 08:48.920\\n',\n",
       " '우리가 Logistic Regression을 이야기할 때 가볍게 이야기했었는데,\\n',\n",
       " '\\n',\n",
       " '08:48.920 --> 08:55.320\\n',\n",
       " '우리가 테일러 시리즈의 어떤 형태를 한번 생각해 보면서,\\n',\n",
       " '\\n',\n",
       " '08:55.320 --> 08:58.120\\n',\n",
       " '우리가 왜 이런 식으로 업데이트하는 파라미터가\\n',\n",
       " '우리가 왜 이런 식으로 업데이트하면 파라미터가\\n',\n",
       " '\\n',\n",
       " '08:58.120 --> 09:02.440\\n',\n",
       " '우리가 목적 함수의 값을 줄이는 방향으로 갈지를 생각해 볼 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '09:02.440 --> 09:04.200\\n',\n",
       " '칼형, 테일러 익스펜션으로 다음과 같이,\\n',\n",
       " '\\n',\n",
       " '09:04.200 --> 09:06.120\\n',\n",
       " '이제 j-offset을 다음과 같이 표현해 볼 수 있습니다.\\n',\n",
       " '이제 j of theta를 다음과 같이 표현해 볼 수가 있겠죠.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'WEBVTT\\n',\n",
       " '\\n',\n",
       " '00:00.000 --> 00:01.080\\n',\n",
       " '수가 있겠죠. 어떤\\n',\n",
       " '\\n',\n",
       " '00:01.080 --> 00:03.440\\n',\n",
       " '포인트 세타 제로에 대해서. 그래서\\n',\n",
       " '\\n',\n",
       " '00:03.440 --> 00:05.860\\n',\n",
       " '근데 여기서 first order approximation 하면은\\n',\n",
       " '\\n',\n",
       " '00:05.860 --> 00:07.520\\n',\n",
       " '다음과 같이 표현이 된다. 그쵸?\\n',\n",
       " '\\n',\n",
       " '00:07.800 --> 00:09.420\\n',\n",
       " '두 번째 세 번째는 이 두 개\\n',\n",
       " '\\n',\n",
       " '00:09.420 --> 00:11.820\\n',\n",
       " '차이가 작을 경우에 제곱 세 제곱\\n',\n",
       " '\\n',\n",
       " '00:11.820 --> 00:13.040\\n',\n",
       " '네 제곱 하는 부분은 사실\\n',\n",
       " '\\n',\n",
       " '00:13.040 --> 00:15.620\\n',\n",
       " '아주 작아질 것이다. 라는 전체 하에\\n',\n",
       " '아주 작아질 것이다. 라는 전제 하에\\n',\n",
       " '\\n',\n",
       " '00:15.620 --> 00:17.680\\n',\n",
       " '다음과 같이 근사할 수 있고요. 근데\\n',\n",
       " '\\n',\n",
       " '00:17.680 --> 00:19.640\\n',\n",
       " '우리가 원하는 건 세타 제로에서\\n',\n",
       " '\\n',\n",
       " '00:19.640 --> 00:21.420\\n',\n",
       " '세타로 갈 때 목적 함수 값이\\n',\n",
       " '\\n',\n",
       " '00:21.420 --> 00:23.640\\n',\n",
       " '감소하는 어떤 결과를\\n',\n",
       " '\\n',\n",
       " '00:23.640 --> 00:25.560\\n',\n",
       " '얻고 싶어요. 그렇다면 그 말인 즉슨\\n',\n",
       " '\\n',\n",
       " '00:25.560 --> 00:27.320\\n',\n",
       " 'j 세타 마이너스 j\\n',\n",
       " '\\n',\n",
       " '00:27.320 --> 00:29.160\\n',\n",
       " 'of 세타 제로가\\n',\n",
       " '\\n',\n",
       " '00:29.160 --> 00:31.480\\n',\n",
       " '다음과 같이 써질 텐데 이게 0보다\\n',\n",
       " '\\n',\n",
       " '00:31.480 --> 00:32.220\\n',\n",
       " '작게 바라는 거죠.\\n',\n",
       " '작길 바라는 거죠.\\n',\n",
       " '\\n',\n",
       " '00:34.020 --> 00:35.600\\n',\n",
       " '그럼 이 방향이 어디냐? 라고 했을 때\\n',\n",
       " '\\n',\n",
       " '00:35.600 --> 00:37.640\\n',\n",
       " '이 업데이트하는 방향을\\n',\n",
       " '\\n',\n",
       " '00:37.640 --> 00:39.600\\n',\n",
       " '다음과 같이 설정하면 되겠다. 이거의 반대방향을\\n',\n",
       " '\\n',\n",
       " '00:39.600 --> 00:41.720\\n',\n",
       " '설정하면 아주 작아지겠다. 라는 식으로\\n',\n",
       " '\\n',\n",
       " '00:41.720 --> 00:43.580\\n',\n",
       " '다음과 같은 식으로\\n',\n",
       " '\\n',\n",
       " '00:43.580 --> 00:45.760\\n',\n",
       " '최종적으로 얻을 수 있다. 라는 부분을\\n',\n",
       " '\\n',\n",
       " '00:45.760 --> 00:47.460\\n',\n",
       " '우리가 정리해 볼 수가\\n',\n",
       " '\\n',\n",
       " '00:47.460 --> 00:49.620\\n',\n",
       " '있었습니다. 그래서 우리가 최적화에\\n',\n",
       " '\\n',\n",
       " '00:49.620 --> 00:51.340\\n',\n",
       " '대한 내용을 알고 있으면 이렇게 왜\\n',\n",
       " '\\n',\n",
       " '00:51.340 --> 00:52.980\\n',\n",
       " '이런 식으로 최적화를 하는지에 대해서\\n',\n",
       " '\\n',\n",
       " '00:52.980 --> 00:55.220\\n',\n",
       " '이해를 해볼 수가 있습니다.\\n',\n",
       " '\\n',\n",
       " '00:56.200 --> 00:57.260\\n',\n",
       " '사실 이제 사이틸런\\n',\n",
       " '사실 이제 사이킷런\\n',\n",
       " '\\n',\n",
       " '00:57.260 --> 00:59.080\\n',\n",
       " '구현상에서는 딱 이런 식으로 최적화\\n',\n",
       " '\\n',\n",
       " '00:59.080 --> 01:00.920\\n',\n",
       " '되는 거 아니고요. 이건 아주 기초적인\\n',\n",
       " '\\n',\n",
       " '01:00.920 --> 01:03.320\\n',\n",
       " '아이디어입니다. 이거를 조금 더 확장한\\n',\n",
       " '\\n',\n",
       " '01:03.320 --> 01:05.160\\n',\n",
       " '버전들이 사용이 되고 있고요. 근데\\n',\n",
       " '\\n',\n",
       " '01:05.160 --> 01:07.300\\n',\n",
       " '이 최적화 방법론에 대해서 아주\\n',\n",
       " '\\n',\n",
       " '01:07.300 --> 01:08.940\\n',\n",
       " '깊이 있게 신도 있게 따지기는 좀\\n',\n",
       " '깊이 있게 심도 있게 따지기는 좀\\n',\n",
       " '\\n',\n",
       " '01:08.940 --> 01:11.000\\n',\n",
       " '너무 과도한 것 같아서 이번 수업에서\\n',\n",
       " '\\n',\n",
       " '01:11.000 --> 01:13.080\\n',\n",
       " '자세히 다루지 않을 일정입니다. 어쨌든\\n',\n",
       " '자세히 다루지 않을 예정입니다. 어쨌든\\n',\n",
       " '\\n',\n",
       " '01:13.080 --> 01:14.920\\n',\n",
       " '이게 기본 아이디어고요.\\n',\n",
       " '\\n',\n",
       " '01:15.180 --> 01:17.260\\n',\n",
       " '이거에 대해서 조금 더 확장된 버전에\\n',\n",
       " '\\n',\n",
       " '01:17.260 --> 01:19.280\\n',\n",
       " '어떤 그레이디언트 기반의 최적화 방법들이\\n',\n",
       " '\\n',\n",
       " '01:19.280 --> 01:20.980\\n',\n",
       " '사용되고 있다. 라는 부분을\\n',\n",
       " '\\n',\n",
       " '01:20.980 --> 01:22.260\\n',\n",
       " '이해를 하시면 좋을 것 같습니다.\\n',\n",
       " '\\n',\n",
       " '01:23.920 --> 01:25.380\\n',\n",
       " '그래서 모델 아키텍처 측면에서\\n',\n",
       " '\\n',\n",
       " '01:25.380 --> 01:26.880\\n',\n",
       " '우리가 어떤 걸 고려해야 되냐. 하이퍼\\n',\n",
       " '\\n',\n",
       " '01:26.880 --> 01:28.840\\n',\n",
       " '프라미터들이 메인 하이퍼 프라미터들이 어떤 게 있냐.\\n',\n",
       " '파라미터들이 메인 하이퍼 파라미터들이 어떤 게 있냐.\\n',\n",
       " '\\n',\n",
       " '01:29.080 --> 01:31.460\\n',\n",
       " '모든 러닝 알고리즘에서 우리 이 수업에서\\n',\n",
       " '\\n',\n",
       " '01:31.460 --> 01:33.160\\n',\n",
       " '가장 강조하는 건 어떤 게\\n',\n",
       " '\\n',\n",
       " '01:33.160 --> 01:34.960\\n',\n",
       " '메인 하이퍼 프라미터냐. 라는 거였습니다.\\n',\n",
       " '메인 하이퍼 파라미터냐. 라는 거였습니다.\\n',\n",
       " '\\n',\n",
       " '01:36.800 --> 01:39.240\\n',\n",
       " '히든 레이어 사이즈. 히든 레이어 몇 개나\\n',\n",
       " '\\n',\n",
       " '01:39.240 --> 01:40.460\\n',\n",
       " '쌓을 것인지. 그리고\\n',\n",
       " '\\n',\n",
       " '01:40.460 --> 01:43.200\\n',\n",
       " '각 히든 레이어의 유닛을 몇 개나 넣을 것인지.\\n',\n",
       " '\\n',\n",
       " '01:43.500 --> 01:44.940\\n',\n",
       " '이 두 가지를 고려하는 게\\n',\n",
       " '\\n',\n",
       " '01:44.940 --> 01:46.460\\n',\n",
       " '필요할 수가 있겠습니다. 그래서\\n',\n",
       " '\\n',\n",
       " '01:46.460 --> 01:48.940\\n',\n",
       " '얘는 이제 각 레이어별로\\n',\n",
       " '\\n',\n",
       " '01:48.940 --> 01:50.980\\n',\n",
       " '몇 개의 유닛을 넣을 건지. 가령\\n',\n",
       " '\\n',\n",
       " '01:50.980 --> 01:53.140\\n',\n",
       " '뭐 50. 이렇게\\n',\n",
       " '\\n',\n",
       " '01:53.140 --> 01:55.020\\n',\n",
       " '넣을 수도 있고요. 점점\\n',\n",
       " '\\n',\n",
       " '01:55.020 --> 01:56.700\\n',\n",
       " '유닛을 작아지게 하고 싶다.\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = pd.DataFrame(train_list,columns=['original'])\n",
    "\n",
    "train = pd.DataFrame()\n",
    "train['timeline'] = origin[origin['original'].str.contains('-->')].reset_index(drop=True)\n",
    "\n",
    "x_index = origin[origin['original'].str.contains('-->')].index + 1\n",
    "train['x'] = origin[origin.index.isin(x_index)].reset_index(drop=True)\n",
    "\n",
    "train['y'] = 0\n",
    "for idx, i in enumerate(x_index):\n",
    "    if origin.loc[(i+1),'original'] == '\\n':\n",
    "        train.loc[idx, 'y'] = origin.loc[i, 'original']\n",
    "    else:\n",
    "        train.loc[idx, 'y'] = origin.loc[(i+1), 'original']\n",
    "\n",
    "train.to_csv(\"강석호교수님.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_test = pd.DataFrame(test_list,columns=['origin_testal'])\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test['timeline'] = origin_test[origin_test['origin_testal'].str.contains('-->')].reset_index(drop=True)\n",
    "\n",
    "x_index = origin_test[origin_test['origin_testal'].str.contains('-->')].index + 1\n",
    "test['x'] = origin_test[origin_test.index.isin(x_index)].reset_index(drop=True)\n",
    "\n",
    "test['y'] = 0\n",
    "for idx, i in enumerate(x_index):\n",
    "    if (origin_test.loc[(i+1),'origin_testal'] == '\\n') or (origin_test.loc[(i+1),'origin_testal'] == '(X)\\n'):\n",
    "        test.loc[idx, 'y'] = origin_test.loc[i, 'origin_testal']\n",
    "    else:\n",
    "        test.loc[idx, 'y'] = origin_test.loc[(i+1), 'origin_testal']\n",
    "\n",
    "test.to_csv(\"강명인교수님.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeline</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00.920 --&gt; 00:05.320\\n</td>\n",
       "      <td>안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분\\n</td>\n",
       "      <td>안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:05.320 --&gt; 00:10.920\\n</td>\n",
       "      <td>오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다\\n</td>\n",
       "      <td>오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:10.920 --&gt; 00:15.920\\n</td>\n",
       "      <td>오늘 할 내용은 뉴로이 네트워크 이구요\\n</td>\n",
       "      <td>오늘 할 내용은 뉴럴 네트워크 이구요\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:15.920 --&gt; 00:20.800\\n</td>\n",
       "      <td>원래 서포트 벡터 머신이 먼저 나와 있는데\\n</td>\n",
       "      <td>원래 서포트 벡터 머신이 먼저 나와 있는데\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:20.800 --&gt; 00:27.240\\n</td>\n",
       "      <td>순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다\\n</td>\n",
       "      <td>순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>39:22.700 --&gt; 39:25.700\\n</td>\n",
       "      <td>조금 더 빠르게 수렴할 수 수렴시킬 수 있고\\n</td>\n",
       "      <td>조금 더 빠르게 수렴할 수 수렴시킬 수 있고\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>39:25.700 --&gt; 39:29.700\\n</td>\n",
       "      <td>그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요\\n</td>\n",
       "      <td>그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>39:29.700 --&gt; 39:32.700\\n</td>\n",
       "      <td>그런데 이제 사실 만약에 사이클론 말고\\n</td>\n",
       "      <td>그런데 이제 사실 만약에 사이킷런 말고\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>39:32.700 --&gt; 39:35.700\\n</td>\n",
       "      <td>여러분이 뭔가 좀 더 텐서플로우나\\n</td>\n",
       "      <td>여러분이 뭔가 좀 더 텐서플로우나\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>39:36.700 --&gt; 39:38.700\\n</td>\n",
       "      <td>스포츠 같은 거 사용해서\\n</td>\n",
       "      <td>파이토치 같은 거 사용해서\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timeline  \\\n",
       "0    00:00.920 --> 00:05.320\\n   \n",
       "1    00:05.320 --> 00:10.920\\n   \n",
       "2    00:10.920 --> 00:15.920\\n   \n",
       "3    00:15.920 --> 00:20.800\\n   \n",
       "4    00:20.800 --> 00:27.240\\n   \n",
       "..                         ...   \n",
       "643  39:22.700 --> 39:25.700\\n   \n",
       "644  39:25.700 --> 39:29.700\\n   \n",
       "645  39:29.700 --> 39:32.700\\n   \n",
       "646  39:32.700 --> 39:35.700\\n   \n",
       "647  39:36.700 --> 39:38.700\\n   \n",
       "\n",
       "                                                   x  \\\n",
       "0                    안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분\\n   \n",
       "1                   오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다\\n   \n",
       "2                            오늘 할 내용은 뉴로이 네트워크 이구요\\n   \n",
       "3                          원래 서포트 벡터 머신이 먼저 나와 있는데\\n   \n",
       "4    순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다\\n   \n",
       "..                                               ...   \n",
       "643                       조금 더 빠르게 수렴할 수 수렴시킬 수 있고\\n   \n",
       "644               그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요\\n   \n",
       "645                          그런데 이제 사실 만약에 사이클론 말고\\n   \n",
       "646                             여러분이 뭔가 좀 더 텐서플로우나\\n   \n",
       "647                                  스포츠 같은 거 사용해서\\n   \n",
       "\n",
       "                                                   y  \n",
       "0                    안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분\\n  \n",
       "1                   오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다\\n  \n",
       "2                             오늘 할 내용은 뉴럴 네트워크 이구요\\n  \n",
       "3                          원래 서포트 벡터 머신이 먼저 나와 있는데\\n  \n",
       "4    순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다\\n  \n",
       "..                                               ...  \n",
       "643                       조금 더 빠르게 수렴할 수 수렴시킬 수 있고\\n  \n",
       "644               그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요\\n  \n",
       "645                          그런데 이제 사실 만약에 사이킷런 말고\\n  \n",
       "646                             여러분이 뭔가 좀 더 텐서플로우나\\n  \n",
       "647                                 파이토치 같은 거 사용해서\\n  \n",
       "\n",
       "[648 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = ''\n",
    "# label = ''\n",
    "# for i in range(len(train)):\n",
    "#     corpus += train.loc[i,'x']\n",
    "#     label += train.loc[i,'y']\n",
    "\n",
    "# corpus = re.sub('\\n', ' ', corpus)\n",
    "# label = re.sub('\\n', ' ', label)    \n",
    "# corpus_list = corpus.split('.')\n",
    "# label_list = label.split('.')\n",
    "# print(len(corpus_list),len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corpus = pd.DataFrame(corpus_list, columns=['X'])\n",
    "# df_label = pd.DataFrame(label_list, columns=['y'])\n",
    "# train = pd.concat([df_corpus, df_label], axis=1)\n",
    "# train = train.iloc[:-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noisy augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from jamo import h2j, j2hcj\n",
    "# import re\n",
    "\n",
    "# def generate_noise(sentence):\n",
    "\n",
    "#     mod_num = len(sentence)//7\n",
    "#     noise = [i for txt in sentence for i in txt]\n",
    "\n",
    "#     choice_idx = random.sample(range(1,len(noise)),mod_num)\n",
    "#     for idx in range(mod_num):\n",
    "#         noise_word = chr(ord(noise[choice_idx[idx]])+np.random.randint(-2,2))\n",
    "#         noise[choice_idx[idx]] = noise_word\n",
    "    \n",
    "#     noisy_data = ''.join(noise)\n",
    "#     noisy_data = re.sub(r'[^A-Za-z가-힣\\.\\,\\?]', ' ', noisy_data) \n",
    "\n",
    "#     return noisy_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_enter(x):\n",
    "    return re.sub('\\n', '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>네 중간고사전 마지막 수업을 시작하겠습니다. 오늘은 지도학습에 대한 여섯번째 수업이고요.</td>\n",
       "      <td>네 중간고사전 마지막 수업을 시작하겠습니다. 오늘은 지도학습에 대한 여섯번째 수업이고요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>저번 시간까지 다양한 지도학습 알고지맨에 대해서 다뤘고, 오늘은 Neural Net...</td>\n",
       "      <td>저번 시간까지 다양한 지도학습 알고리즘에 대해서 다뤘고, 오늘은 Neural Net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그래서 Neural Network가 어떻게 클래시피케이션 또는 리그레이션 문제에 적...</td>\n",
       "      <td>그래서 Neural Network가 어떻게 클래시피케이션 또는 리그레이션 문제에 적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그리고 또 어떻게 우리가 사이클런을 이용해서 구현할 수 있을지에 대해서 다룰 예정이고요.</td>\n",
       "      <td>그리고 또 어떻게 우리가 사이킷런을 이용해서 구현할 수 있을지에 대해서 다룰 예정이고요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그 다음에는 이제 우리가 전체적인 슈퍼바이스 러닝 프레임웍에서 고려할 만한 다양한 ...</td>\n",
       "      <td>그 다음에는 이제 우리가 전체적인 슈퍼바이스 러닝 프레임웍에서 고려할 만한 다양한 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>상당히 딥러닝에 대한 어떤 전반적인 배경,</td>\n",
       "      <td>상당히 딥러닝에 대한 어떤 전반적인 배경,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>그리고 어떤 현재 어디에 있는가,</td>\n",
       "      <td>그리고 어떤 현재 어디에 있는가,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>그리고 앞으로 어떤 방향으로 나올 것인가</td>\n",
       "      <td>그리고 앞으로 어떤 방향으로 나아갈 것인가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>이런 것들을 이해하는데 상당히 도움이 많이 되는 논문인 것 같습니다.</td>\n",
       "      <td>이런 것들을 이해하는데 상당히 도움이 많이 되는 논문인 것 같습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>그래서 한번 읽어보시면 여러분들에게 좋은 인사이트를 주지 않을까 싶습니다.</td>\n",
       "      <td>그래서 한번 읽어보시면 여러분들에게 좋은 인사이트를 주지 않을까 싶습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     X  \\\n",
       "0    네 중간고사전 마지막 수업을 시작하겠습니다. 오늘은 지도학습에 대한 여섯번째 수업이고요.   \n",
       "1    저번 시간까지 다양한 지도학습 알고지맨에 대해서 다뤘고, 오늘은 Neural Net...   \n",
       "2    그래서 Neural Network가 어떻게 클래시피케이션 또는 리그레이션 문제에 적...   \n",
       "3    그리고 또 어떻게 우리가 사이클런을 이용해서 구현할 수 있을지에 대해서 다룰 예정이고요.   \n",
       "4    그 다음에는 이제 우리가 전체적인 슈퍼바이스 러닝 프레임웍에서 고려할 만한 다양한 ...   \n",
       "..                                                 ...   \n",
       "800                            상당히 딥러닝에 대한 어떤 전반적인 배경,   \n",
       "801                                 그리고 어떤 현재 어디에 있는가,   \n",
       "802                             그리고 앞으로 어떤 방향으로 나올 것인가   \n",
       "803             이런 것들을 이해하는데 상당히 도움이 많이 되는 논문인 것 같습니다.   \n",
       "804          그래서 한번 읽어보시면 여러분들에게 좋은 인사이트를 주지 않을까 싶습니다.   \n",
       "\n",
       "                                                     y  \n",
       "0    네 중간고사전 마지막 수업을 시작하겠습니다. 오늘은 지도학습에 대한 여섯번째 수업이고요.  \n",
       "1    저번 시간까지 다양한 지도학습 알고리즘에 대해서 다뤘고, 오늘은 Neural Net...  \n",
       "2    그래서 Neural Network가 어떻게 클래시피케이션 또는 리그레이션 문제에 적...  \n",
       "3    그리고 또 어떻게 우리가 사이킷런을 이용해서 구현할 수 있을지에 대해서 다룰 예정이고요.  \n",
       "4    그 다음에는 이제 우리가 전체적인 슈퍼바이스 러닝 프레임웍에서 고려할 만한 다양한 ...  \n",
       "..                                                 ...  \n",
       "800                            상당히 딥러닝에 대한 어떤 전반적인 배경,  \n",
       "801                                 그리고 어떤 현재 어디에 있는가,  \n",
       "802                            그리고 앞으로 어떤 방향으로 나아갈 것인가  \n",
       "803             이런 것들을 이해하는데 상당히 도움이 많이 되는 논문인 것 같습니다.  \n",
       "804          그래서 한번 읽어보시면 여러분들에게 좋은 인사이트를 주지 않을까 싶습니다.  \n",
       "\n",
       "[805 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['x','y']]\n",
    "train['x'] = train['x'].apply(drop_enter)\n",
    "train['y'] = train['y'].apply(drop_enter)\n",
    "train.rename({'x':'X'}, axis=1, inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"강석호교수님.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분</td>\n",
       "      <td>안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다</td>\n",
       "      <td>오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>오늘 할 내용은 뉴로이 네트워크 이구요</td>\n",
       "      <td>오늘 할 내용은 뉴럴 네트워크 이구요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원래 서포트 벡터 머신이 먼저 나와 있는데</td>\n",
       "      <td>원래 서포트 벡터 머신이 먼저 나와 있는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다</td>\n",
       "      <td>순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>조금 더 빠르게 수렴할 수 수렴시킬 수 있고</td>\n",
       "      <td>조금 더 빠르게 수렴할 수 수렴시킬 수 있고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요</td>\n",
       "      <td>그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>그런데 이제 사실 만약에 사이클론 말고</td>\n",
       "      <td>그런데 이제 사실 만약에 사이킷런 말고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>여러분이 뭔가 좀 더 텐서플로우나</td>\n",
       "      <td>여러분이 뭔가 좀 더 텐서플로우나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>스포츠 같은 거 사용해서</td>\n",
       "      <td>파이토치 같은 거 사용해서</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 X  \\\n",
       "0                    안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분   \n",
       "1                   오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다   \n",
       "2                            오늘 할 내용은 뉴로이 네트워크 이구요   \n",
       "3                          원래 서포트 벡터 머신이 먼저 나와 있는데   \n",
       "4    순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다   \n",
       "..                                             ...   \n",
       "643                       조금 더 빠르게 수렴할 수 수렴시킬 수 있고   \n",
       "644               그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요   \n",
       "645                          그런데 이제 사실 만약에 사이클론 말고   \n",
       "646                             여러분이 뭔가 좀 더 텐서플로우나   \n",
       "647                                  스포츠 같은 거 사용해서   \n",
       "\n",
       "                                                 y  \n",
       "0                    안녕하세요 데이터과학을 위한 프로그래밍 수강생 여러분  \n",
       "1                   오늘 슈퍼바이스러닝 다섯번째 시간 시작하도록 하겠습니다  \n",
       "2                             오늘 할 내용은 뉴럴 네트워크 이구요  \n",
       "3                          원래 서포트 벡터 머신이 먼저 나와 있는데  \n",
       "4    순서를 바꿔서 인공신경망, 뉴로이 네트워크에 관련된 내용부터 진행하도록 하겠습니다  \n",
       "..                                             ...  \n",
       "643                       조금 더 빠르게 수렴할 수 수렴시킬 수 있고  \n",
       "644               그리고 성능도 좋을 수 있다 라는 일반적인 이야기가 있고요  \n",
       "645                          그런데 이제 사실 만약에 사이킷런 말고  \n",
       "646                             여러분이 뭔가 좀 더 텐서플로우나  \n",
       "647                                 파이토치 같은 거 사용해서  \n",
       "\n",
       "[648 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['x','y']]\n",
    "test['x'] = test['x'].apply(drop_enter)\n",
    "test['y'] = test['y'].apply(drop_enter)\n",
    "test.rename({'x':'X'}, axis=1, inplace=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"강명인교수님.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_train = pd.DataFrame()\n",
    "# for i in range(70):\n",
    "#     exec(f\"train_{i} = train.copy()\")\n",
    "#     exec(f\"train_{i}['X'] = train_{i}['X'].apply(generate_noise)\")\n",
    "#     exec(f\"train_{i}['y'] = train_{i}['y'].apply(drop_enter)\")\n",
    "#     exec(f\"aug_train = pd.concat([aug_train, train_{i}])\")\n",
    "\n",
    "# aug_train = aug_train[['X','y']].reset_index(drop=True)\n",
    "# aug_train.to_csv(\"aug_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_train.to_excel(\"aug_train.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
